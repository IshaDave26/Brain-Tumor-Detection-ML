# -*- coding: utf-8 -*-
"""A066_A102_A108_CNN+ViT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O0OkFRQ97RdGAlqx6UqzOGQJcj7_cECo
"""

#importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder

import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

from keras.preprocessing.image import ImageDataGenerator
from keras.utils import array_to_img, img_to_array, load_img

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.applications import EfficientNetV2S

# Load the image data and labels
data = pd.read_csv('/content/Brain Tumor test.csv')

# Modify the 'Image' column to include the full path to the images
data['Image'] = '/content/Brain Tumor/' + data['Image']

# Load the images and their labels into arrays
X = []
Y = []
for i in range(len(data)):
    img = Image.open(data['Image'][i] + '.jpg')
    img = img.resize((224, 224))
    X.append(np.array(img))
    Y.append(data['Class'][i])
X = np.array(X) / 255.0

# Convert the labels to numerical values
le = LabelEncoder()
Y = le.fit_transform(Y)

# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=41)

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Load the pre-trained EfficientNetV2S model
efficientnetv2s = EfficientNetV2S(include_top=False, input_shape=(224, 224, 3))

# Freeze the pre-trained layers
for layer in efficientnetv2s.layers:
    layer.trainable = False

# Add new layers on top of the pre-trained model
model = tf.keras.Sequential([
    efficientnetv2s,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(datagen.flow(X_train, Y_train, batch_size=32),
                    epochs=10,
                    validation_data=(X_test, Y_test))

# Visualize the training loss and accuracy across epochs
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

test_loss, test_acc = model.evaluate(np.array(X_test), np.array(Y_test))
print('Test accuracy:', test_acc)
#plotting confusion matrix
import matplotlib.pyplot as plt
import seaborn as sns

Y_pred = model.predict(X_test)
Y_pred_classes = np.round(Y_pred)
confusion_mtx = confusion_matrix(Y_test, Y_pred_classes)

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_mtx, annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()